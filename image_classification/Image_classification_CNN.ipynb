{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# for CNN and NN models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing image data\n",
    "\n",
    "The dataset has been retreived from  https://www.kaggle.com/datasets/imbikramsaha/caltech-101\n",
    "\n",
    "The Caltech101 dataset contains images from 101 object categories (e.g., “helicopter”, “elephant” and “chair” etc.) and a background category that contains the images not from the 101 object categories. For each object category, there are about 40 to 800 images, while most classes have about 50 images. The resolution of the image is roughly about 300×200 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a csv containing the file paths along with the folder names for reading them easily into the python environment.\n",
    "final_df=pd.DataFrame()\n",
    "d=\"101_ObjectCategories\"\n",
    "for path in os.listdir(d):\n",
    "    df = pd.DataFrame()\n",
    "    Files_list = []\n",
    "    for files in os.listdir(d+\"\\\\\"+path):\n",
    "        Files_list.append(d+\"\\\\\"+path+\"\\\\\"+files)\n",
    "    df[\"files\"]=pd.Series(Files_list)\n",
    "    df[\"folder\"]=path\n",
    "    final_df = final_df.append(df)\n",
    "    \n",
    "final_df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the top 5 groups for processing\n",
    "\n",
    "Due to the large quantity of files and their size, i am filtering out and will be suing the top 5 folders in terms of number of files in each folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "folder\n",
       "airplanes            800\n",
       "Motorbikes           798\n",
       "BACKGROUND_Google    468\n",
       "Faces                435\n",
       "Faces_easy           435\n",
       "watch                239\n",
       "Leopards             200\n",
       "bonsai               128\n",
       "car_side             123\n",
       "ketch                114\n",
       "chandelier           107\n",
       "hawksbill            100\n",
       "grand_piano           99\n",
       "brain                 98\n",
       "butterfly             91\n",
       "helicopter            88\n",
       "menorah               87\n",
       "starfish              86\n",
       "kangaroo              86\n",
       "trilobite             86\n",
       "buddha                85\n",
       "ewer                  85\n",
       "sunflower             85\n",
       "scorpion              84\n",
       "revolver              82\n",
       "laptop                81\n",
       "ibis                  80\n",
       "llama                 78\n",
       "minaret               76\n",
       "umbrella              75\n",
       "                    ... \n",
       "pagoda                47\n",
       "cougar_body           47\n",
       "beaver                46\n",
       "flamingo_head         45\n",
       "pigeon                45\n",
       "stapler               45\n",
       "mandolin              43\n",
       "cannon                43\n",
       "brontosaurus          43\n",
       "headphone             42\n",
       "ant                   42\n",
       "anchor                42\n",
       "lobster               41\n",
       "saxophone             40\n",
       "mayfly                40\n",
       "wrench                39\n",
       "scissors              39\n",
       "okapi                 39\n",
       "panda                 38\n",
       "water_lilly           37\n",
       "octopus               35\n",
       "snoopy                35\n",
       "strawberry            35\n",
       "wild_cat              34\n",
       "platypus              34\n",
       "gerenuk               34\n",
       "garfield              34\n",
       "binocular             33\n",
       "metronome             32\n",
       "inline_skate          31\n",
       "Name: files, Length: 102, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = final_df.groupby(\"folder\")[\"files\"].count()\n",
    "\n",
    "grouped_df.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df= final_df[~(final_df[\"folder\"].isin([\"airplanes\", \"Motorbikes\",\"BACKGROUND_Google\",\"Faces\", \"Faces_easy\" ]))]\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images\n",
    "\n",
    "Reading all the images into a dataframe with the folder name and the file path, the images are read as arrays by resizing into 300X300 pixels. Cubic interpolation  takes into account more neighboring pixels when calculating the values of pixels at the target location, resulting in a smoother and more visually appealing result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"image\"]= final_df[\"files\"].apply(lambda x: cv2.resize(cv2.imread(str(x), cv2.IMREAD_COLOR),(300,200), interpolation=cv2.INTER_CUBIC)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>folder</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...</td>\n",
       "      <td>accordion</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...</td>\n",
       "      <td>accordion</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...</td>\n",
       "      <td>accordion</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...</td>\n",
       "      <td>accordion</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...</td>\n",
       "      <td>accordion</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               files     folder  \\\n",
       "0  C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...  accordion   \n",
       "1  C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...  accordion   \n",
       "2  C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...  accordion   \n",
       "3  C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...  accordion   \n",
       "4  C:\\Users\\info-06\\Desktop\\Game#\\client work\\bha...  accordion   \n",
       "\n",
       "                                               image  \n",
       "0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "2  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "3  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "4  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6209, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the images to numpy arrays\n",
    "X = np.ndarray((6209, 200, 300, 3), dtype=np.uint8)\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in final_df.iterrows():\n",
    "    X[index] = row[\"image\"]\n",
    "    Y.insert(index,row[\"folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6209, 200, 300, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the data\n",
    "\n",
    "Encoding the labels and converting them into numbers, each label is given a unique number so the model can classify the arrays of the image into their respective encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_integer_encoded = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to high volume of data we need to delete a few variables from memory to be able to further the processing required\n",
    "\n",
    "del Y\n",
    "del final_df\n",
    "del grouped_df\n",
    "X_normalized = X.astype(np.float64)\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values in an image typically range from 0 to 255 for an 8-bit image, where 0 represents black and 255 represents white. When you perform various image processing tasks or use machine learning algorithms, it can be beneficial to have pixel values in a standardized range, often between 0 and 1. Normalization is a common technique used to achieve this standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for index in X_normalized:\n",
    "    X_normalized[i] = index/255.\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the dependent variable to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_one_hot = to_categorical(Y_integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to high volume of data we need to delete a few variables from memory to be able to further the processing required\n",
    "\n",
    "del Y_integer_encoded\n",
    "del label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_normalized, Y_one_hot, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions:  (200, 300, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 200, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 200, 300, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 100, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 100, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 100, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 97)                24929     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 97)                0         \n",
      "=================================================================\n",
      "Total params: 1,233,473\n",
      "Trainable params: 1,233,473\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "# Creating the neural network model\n",
    "model = Sequential()\n",
    "print(\"Input dimensions: \",X_train.shape[1:])\n",
    "\n",
    "# These lines add the first convolutional layer to the model. \n",
    "# It consists of 32 filters of size 3x3. The 'relu' activation function is applied after each convolution operation, \n",
    "# and a max-pooling layer with a 2x2 pool size follows.\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# The pattern is repeated for a second convolutional layer.\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# This line adds a flattening layer that transforms the output of the convolutional layers into a one-dimensional vector. \n",
    "# This is necessary before feeding the data into fully connected layers.\n",
    "model.add(Flatten())\n",
    "\n",
    "# These lines add a fully connected layer with 256 neurons, followed by a ReLU activation function.\n",
    "# This layer processes the flattened output from the previous layers.\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# This code adds the output layer with a number of neurons equal to num_classes, \n",
    "# which represents the number of classes in the classification problem. \n",
    "# The softmax activation function is used to convert the network's final output into class probabilities.\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# This line prints a summary of the entire network architecture, \n",
    "# including the number of parameters in each layer and the overall model size.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/10\n",
      "4346/4346 [==============================] - 11s 3ms/step - loss: 4.5153 - acc: 0.0403 - val_loss: 4.4140 - val_acc: 0.0763\n",
      "Epoch 2/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 4.2447 - acc: 0.1010 - val_loss: 4.1066 - val_acc: 0.1407\n",
      "Epoch 3/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.9434 - acc: 0.1519 - val_loss: 3.7939 - val_acc: 0.2052\n",
      "Epoch 4/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.6178 - acc: 0.2046 - val_loss: 3.5077 - val_acc: 0.2309\n",
      "Epoch 5/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.3217 - acc: 0.2531 - val_loss: 3.3025 - val_acc: 0.2696\n",
      "Epoch 6/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.0783 - acc: 0.2931 - val_loss: 3.0644 - val_acc: 0.3083\n",
      "Epoch 7/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.7861 - acc: 0.3502 - val_loss: 2.8714 - val_acc: 0.3373\n",
      "Epoch 8/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.5162 - acc: 0.3971 - val_loss: 2.7907 - val_acc: 0.3663\n",
      "Epoch 9/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.2286 - acc: 0.4478 - val_loss: 2.7009 - val_acc: 0.3910\n",
      "Epoch 10/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.0241 - acc: 0.4979 - val_loss: 2.6859 - val_acc: 0.3996\n"
     ]
    }
   ],
   "source": [
    "# compile the model to use categorical cross-entropy loss function and adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.compile() is a method used to configure the training process of the neural network.\n",
    "* loss='categorical_crossentropy' specifies the loss function that the network will optimize during training. In this case, it's categorical cross-entropy, which is commonly used for multi-class classification problems.\n",
    "* optimizer='adam' specifies the optimization algorithm to be used during training. 'Adam' is a popular choice as it adapts the learning rate during training.\n",
    "* metrics=['accuracy'] specifies that you want to monitor the accuracy of the model during training as an evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.0693324206887\n",
      "Test accuracy: 0.204356001922\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is very low. Trying out different layer configurations to see if the model accuracy can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions:  (224, 224, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 97)                24929     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 97)                0         \n",
      "=================================================================\n",
      "Total params: 1,233,473\n",
      "Trainable params: 1,233,473\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "# creating the network with dropout layer\n",
    "model = Sequential()\n",
    "print(\"Input dimensions: \",X_train.shape[1:])\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/10\n",
      "4346/4346 [==============================] - 11s 3ms/step - loss: 4.5153 - acc: 0.0403 - val_loss: 4.4140 - val_acc: 0.0763\n",
      "Epoch 2/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 4.2447 - acc: 0.1010 - val_loss: 4.1066 - val_acc: 0.1407\n",
      "Epoch 3/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.9434 - acc: 0.1519 - val_loss: 3.7939 - val_acc: 0.2052\n",
      "Epoch 4/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.6178 - acc: 0.2046 - val_loss: 3.5077 - val_acc: 0.2309\n",
      "Epoch 5/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.3217 - acc: 0.2531 - val_loss: 3.3025 - val_acc: 0.2696\n",
      "Epoch 6/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 3.0783 - acc: 0.2931 - val_loss: 3.0644 - val_acc: 0.3083\n",
      "Epoch 7/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.7861 - acc: 0.3502 - val_loss: 2.8714 - val_acc: 0.3373\n",
      "Epoch 8/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.5162 - acc: 0.3971 - val_loss: 2.7907 - val_acc: 0.3663\n",
      "Epoch 9/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.2286 - acc: 0.4478 - val_loss: 2.7009 - val_acc: 0.3910\n",
      "Epoch 10/10\n",
      "4346/4346 [==============================] - 10s 2ms/step - loss: 2.0241 - acc: 0.4979 - val_loss: 2.6859 - val_acc: 0.3996\n"
     ]
    }
   ],
   "source": [
    "# compile the model to use categorical cross-entropy loss function and adadelta optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_validation, Y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.891112345432\n",
      "Test accuracy: 0.409592212343\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is higher but probably due to overfitting. Next, we will try a pre-trained model to see the performance can be further improved or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transfer_learning_model.layers[:280]:\n",
    "    layer.trainable = False\n",
    "for layer in transfer_learning_model.layers[280:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code allows you to specify which layers should be trainable (have their weights updated during training) and which layers should remain frozen (not updated) when you're using a pre-trained model as a starting point for a new task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)              (None, None, None, 32 864         input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchNo (None, None, None, 32 96          conv2d_283[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_283 (Activation)      (None, None, None, 32 0           batch_normalization_283[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)              (None, None, None, 32 9216        activation_283[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchNo (None, None, None, 32 96          conv2d_284[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_284 (Activation)      (None, None, None, 32 0           batch_normalization_284[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)              (None, None, None, 64 18432       activation_284[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchNo (None, None, None, 64 192         conv2d_285[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_285 (Activation)      (None, None, None, 64 0           batch_normalization_285[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, None, None, 64 0           activation_285[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)              (None, None, None, 80 5120        max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchNo (None, None, None, 80 240         conv2d_286[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_286 (Activation)      (None, None, None, 80 0           batch_normalization_286[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)              (None, None, None, 19 138240      activation_286[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchNo (None, None, None, 19 576         conv2d_287[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_287 (Activation)      (None, None, None, 19 0           batch_normalization_287[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D)  (None, None, None, 19 0           activation_287[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchNo (None, None, None, 64 192         conv2d_291[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_291 (Activation)      (None, None, None, 64 0           batch_normalization_291[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)              (None, None, None, 48 9216        max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)              (None, None, None, 96 55296       activation_291[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchNo (None, None, None, 48 144         conv2d_289[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchNo (None, None, None, 96 288         conv2d_292[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_289 (Activation)      (None, None, None, 48 0           batch_normalization_289[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_292 (Activation)      (None, None, None, 96 0           batch_normalization_292[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePoo (None, None, None, 19 0           max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)              (None, None, None, 64 76800       activation_289[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)              (None, None, None, 96 82944       activation_292[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)              (None, None, None, 32 6144        average_pooling2d_28[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchNo (None, None, None, 64 192         conv2d_288[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchNo (None, None, None, 64 192         conv2d_290[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchNo (None, None, None, 96 288         conv2d_293[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchNo (None, None, None, 32 96          conv2d_294[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_288 (Activation)      (None, None, None, 64 0           batch_normalization_288[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_290 (Activation)      (None, None, None, 64 0           batch_normalization_290[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_293 (Activation)      (None, None, None, 96 0           batch_normalization_293[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_294 (Activation)      (None, None, None, 32 0           batch_normalization_294[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_288[0][0]             \n",
      "                                                                   activation_290[0][0]             \n",
      "                                                                   activation_293[0][0]             \n",
      "                                                                   activation_294[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchNo (None, None, None, 64 192         conv2d_298[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_298 (Activation)      (None, None, None, 64 0           batch_normalization_298[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)              (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)              (None, None, None, 96 55296       activation_298[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchNo (None, None, None, 48 144         conv2d_296[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchNo (None, None, None, 96 288         conv2d_299[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_296 (Activation)      (None, None, None, 48 0           batch_normalization_296[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_299 (Activation)      (None, None, None, 96 0           batch_normalization_299[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePoo (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)              (None, None, None, 64 76800       activation_296[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)              (None, None, None, 96 82944       activation_299[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)              (None, None, None, 64 16384       average_pooling2d_29[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchNo (None, None, None, 64 192         conv2d_295[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchNo (None, None, None, 64 192         conv2d_297[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchNo (None, None, None, 96 288         conv2d_300[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchNo (None, None, None, 64 192         conv2d_301[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_295 (Activation)      (None, None, None, 64 0           batch_normalization_295[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_297 (Activation)      (None, None, None, 64 0           batch_normalization_297[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_300 (Activation)      (None, None, None, 96 0           batch_normalization_300[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_301 (Activation)      (None, None, None, 64 0           batch_normalization_301[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_295[0][0]             \n",
      "                                                                   activation_297[0][0]             \n",
      "                                                                   activation_300[0][0]             \n",
      "                                                                   activation_301[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchNo (None, None, None, 64 192         conv2d_305[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_305 (Activation)      (None, None, None, 64 0           batch_normalization_305[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)              (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)              (None, None, None, 96 55296       activation_305[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchNo (None, None, None, 48 144         conv2d_303[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchNo (None, None, None, 96 288         conv2d_306[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_303 (Activation)      (None, None, None, 48 0           batch_normalization_303[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_306 (Activation)      (None, None, None, 96 0           batch_normalization_306[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePoo (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)              (None, None, None, 64 76800       activation_303[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)              (None, None, None, 96 82944       activation_306[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)              (None, None, None, 64 18432       average_pooling2d_30[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchNo (None, None, None, 64 192         conv2d_302[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchNo (None, None, None, 64 192         conv2d_304[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchNo (None, None, None, 96 288         conv2d_307[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchNo (None, None, None, 64 192         conv2d_308[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_302 (Activation)      (None, None, None, 64 0           batch_normalization_302[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_304 (Activation)      (None, None, None, 64 0           batch_normalization_304[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_307 (Activation)      (None, None, None, 96 0           batch_normalization_307[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_308 (Activation)      (None, None, None, 64 0           batch_normalization_308[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_302[0][0]             \n",
      "                                                                   activation_304[0][0]             \n",
      "                                                                   activation_307[0][0]             \n",
      "                                                                   activation_308[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)              (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchNo (None, None, None, 64 192         conv2d_310[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_310 (Activation)      (None, None, None, 64 0           batch_normalization_310[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)              (None, None, None, 96 55296       activation_310[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchNo (None, None, None, 96 288         conv2d_311[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_311 (Activation)      (None, None, None, 96 0           batch_normalization_311[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)              (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)              (None, None, None, 96 82944       activation_311[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchNo (None, None, None, 38 1152        conv2d_309[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchNo (None, None, None, 96 288         conv2d_312[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_309 (Activation)      (None, None, None, 38 0           batch_normalization_309[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_312 (Activation)      (None, None, None, 96 0           batch_normalization_312[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D)  (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_309[0][0]             \n",
      "                                                                   activation_312[0][0]             \n",
      "                                                                   max_pooling2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchNo (None, None, None, 12 384         conv2d_317[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_317 (Activation)      (None, None, None, 12 0           batch_normalization_317[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)              (None, None, None, 12 114688      activation_317[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchNo (None, None, None, 12 384         conv2d_318[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_318 (Activation)      (None, None, None, 12 0           batch_normalization_318[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)              (None, None, None, 12 114688      activation_318[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchNo (None, None, None, 12 384         conv2d_314[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchNo (None, None, None, 12 384         conv2d_319[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_314 (Activation)      (None, None, None, 12 0           batch_normalization_314[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_319 (Activation)      (None, None, None, 12 0           batch_normalization_319[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)              (None, None, None, 12 114688      activation_314[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)              (None, None, None, 12 114688      activation_319[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchNo (None, None, None, 12 384         conv2d_315[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchNo (None, None, None, 12 384         conv2d_320[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_315 (Activation)      (None, None, None, 12 0           batch_normalization_315[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_320 (Activation)      (None, None, None, 12 0           batch_normalization_320[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePoo (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)              (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)              (None, None, None, 19 172032      activation_315[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)              (None, None, None, 19 172032      activation_320[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_31[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchNo (None, None, None, 19 576         conv2d_313[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchNo (None, None, None, 19 576         conv2d_316[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchNo (None, None, None, 19 576         conv2d_321[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchNo (None, None, None, 19 576         conv2d_322[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_313 (Activation)      (None, None, None, 19 0           batch_normalization_313[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_316 (Activation)      (None, None, None, 19 0           batch_normalization_316[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_321 (Activation)      (None, None, None, 19 0           batch_normalization_321[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_322 (Activation)      (None, None, None, 19 0           batch_normalization_322[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_313[0][0]             \n",
      "                                                                   activation_316[0][0]             \n",
      "                                                                   activation_321[0][0]             \n",
      "                                                                   activation_322[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchNo (None, None, None, 16 480         conv2d_327[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_327 (Activation)      (None, None, None, 16 0           batch_normalization_327[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)              (None, None, None, 16 179200      activation_327[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchNo (None, None, None, 16 480         conv2d_328[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_328 (Activation)      (None, None, None, 16 0           batch_normalization_328[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)              (None, None, None, 16 179200      activation_328[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchNo (None, None, None, 16 480         conv2d_324[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchNo (None, None, None, 16 480         conv2d_329[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_324 (Activation)      (None, None, None, 16 0           batch_normalization_324[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_329 (Activation)      (None, None, None, 16 0           batch_normalization_329[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)              (None, None, None, 16 179200      activation_324[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)              (None, None, None, 16 179200      activation_329[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchNo (None, None, None, 16 480         conv2d_325[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchNo (None, None, None, 16 480         conv2d_330[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_325 (Activation)      (None, None, None, 16 0           batch_normalization_325[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_330 (Activation)      (None, None, None, 16 0           batch_normalization_330[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePoo (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)              (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)              (None, None, None, 19 215040      activation_325[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)              (None, None, None, 19 215040      activation_330[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_32[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchNo (None, None, None, 19 576         conv2d_323[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchNo (None, None, None, 19 576         conv2d_326[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchNo (None, None, None, 19 576         conv2d_331[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchNo (None, None, None, 19 576         conv2d_332[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_323 (Activation)      (None, None, None, 19 0           batch_normalization_323[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_326 (Activation)      (None, None, None, 19 0           batch_normalization_326[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_331 (Activation)      (None, None, None, 19 0           batch_normalization_331[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_332 (Activation)      (None, None, None, 19 0           batch_normalization_332[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_323[0][0]             \n",
      "                                                                   activation_326[0][0]             \n",
      "                                                                   activation_331[0][0]             \n",
      "                                                                   activation_332[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchNo (None, None, None, 16 480         conv2d_337[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_337 (Activation)      (None, None, None, 16 0           batch_normalization_337[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)              (None, None, None, 16 179200      activation_337[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchNo (None, None, None, 16 480         conv2d_338[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_338 (Activation)      (None, None, None, 16 0           batch_normalization_338[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)              (None, None, None, 16 179200      activation_338[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchNo (None, None, None, 16 480         conv2d_334[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchNo (None, None, None, 16 480         conv2d_339[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_334 (Activation)      (None, None, None, 16 0           batch_normalization_334[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_339 (Activation)      (None, None, None, 16 0           batch_normalization_339[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)              (None, None, None, 16 179200      activation_334[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)              (None, None, None, 16 179200      activation_339[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchNo (None, None, None, 16 480         conv2d_335[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchNo (None, None, None, 16 480         conv2d_340[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_335 (Activation)      (None, None, None, 16 0           batch_normalization_335[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_340 (Activation)      (None, None, None, 16 0           batch_normalization_340[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePoo (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)              (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)              (None, None, None, 19 215040      activation_335[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)              (None, None, None, 19 215040      activation_340[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_33[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchNo (None, None, None, 19 576         conv2d_333[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchNo (None, None, None, 19 576         conv2d_336[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchNo (None, None, None, 19 576         conv2d_341[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchNo (None, None, None, 19 576         conv2d_342[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_333 (Activation)      (None, None, None, 19 0           batch_normalization_333[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_336 (Activation)      (None, None, None, 19 0           batch_normalization_336[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_341 (Activation)      (None, None, None, 19 0           batch_normalization_341[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_342 (Activation)      (None, None, None, 19 0           batch_normalization_342[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_333[0][0]             \n",
      "                                                                   activation_336[0][0]             \n",
      "                                                                   activation_341[0][0]             \n",
      "                                                                   activation_342[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchNo (None, None, None, 19 576         conv2d_347[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_347 (Activation)      (None, None, None, 19 0           batch_normalization_347[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)              (None, None, None, 19 258048      activation_347[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchNo (None, None, None, 19 576         conv2d_348[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_348 (Activation)      (None, None, None, 19 0           batch_normalization_348[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)              (None, None, None, 19 258048      activation_348[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchNo (None, None, None, 19 576         conv2d_344[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchNo (None, None, None, 19 576         conv2d_349[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_344 (Activation)      (None, None, None, 19 0           batch_normalization_344[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_349 (Activation)      (None, None, None, 19 0           batch_normalization_349[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)              (None, None, None, 19 258048      activation_344[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)              (None, None, None, 19 258048      activation_349[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchNo (None, None, None, 19 576         conv2d_345[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchNo (None, None, None, 19 576         conv2d_350[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_345 (Activation)      (None, None, None, 19 0           batch_normalization_345[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_350 (Activation)      (None, None, None, 19 0           batch_normalization_350[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePoo (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)              (None, None, None, 19 258048      activation_345[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)              (None, None, None, 19 258048      activation_350[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_34[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchNo (None, None, None, 19 576         conv2d_343[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchNo (None, None, None, 19 576         conv2d_346[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchNo (None, None, None, 19 576         conv2d_351[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchNo (None, None, None, 19 576         conv2d_352[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_343 (Activation)      (None, None, None, 19 0           batch_normalization_343[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_346 (Activation)      (None, None, None, 19 0           batch_normalization_346[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_351 (Activation)      (None, None, None, 19 0           batch_normalization_351[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_352 (Activation)      (None, None, None, 19 0           batch_normalization_352[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_343[0][0]             \n",
      "                                                                   activation_346[0][0]             \n",
      "                                                                   activation_351[0][0]             \n",
      "                                                                   activation_352[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchNo (None, None, None, 19 576         conv2d_355[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_355 (Activation)      (None, None, None, 19 0           batch_normalization_355[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)              (None, None, None, 19 258048      activation_355[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchNo (None, None, None, 19 576         conv2d_356[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_356 (Activation)      (None, None, None, 19 0           batch_normalization_356[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)              (None, None, None, 19 258048      activation_356[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchNo (None, None, None, 19 576         conv2d_353[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchNo (None, None, None, 19 576         conv2d_357[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_353 (Activation)      (None, None, None, 19 0           batch_normalization_353[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_357 (Activation)      (None, None, None, 19 0           batch_normalization_357[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)              (None, None, None, 32 552960      activation_353[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)              (None, None, None, 19 331776      activation_357[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchNo (None, None, None, 32 960         conv2d_354[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchNo (None, None, None, 19 576         conv2d_358[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_354 (Activation)      (None, None, None, 32 0           batch_normalization_354[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_358 (Activation)      (None, None, None, 19 0           batch_normalization_358[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D)  (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_354[0][0]             \n",
      "                                                                   activation_358[0][0]             \n",
      "                                                                   max_pooling2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)              (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchNo (None, None, None, 44 1344        conv2d_363[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_363 (Activation)      (None, None, None, 44 0           batch_normalization_363[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)              (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)              (None, None, None, 38 1548288     activation_363[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchNo (None, None, None, 38 1152        conv2d_360[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchNo (None, None, None, 38 1152        conv2d_364[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_360 (Activation)      (None, None, None, 38 0           batch_normalization_360[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_364 (Activation)      (None, None, None, 38 0           batch_normalization_364[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)              (None, None, None, 38 442368      activation_360[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)              (None, None, None, 38 442368      activation_360[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)              (None, None, None, 38 442368      activation_364[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)              (None, None, None, 38 442368      activation_364[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePoo (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)              (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchNo (None, None, None, 38 1152        conv2d_361[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchNo (None, None, None, 38 1152        conv2d_362[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchNo (None, None, None, 38 1152        conv2d_365[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchNo (None, None, None, 38 1152        conv2d_366[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)              (None, None, None, 19 245760      average_pooling2d_35[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchNo (None, None, None, 32 960         conv2d_359[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_361 (Activation)      (None, None, None, 38 0           batch_normalization_361[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_362 (Activation)      (None, None, None, 38 0           batch_normalization_362[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_365 (Activation)      (None, None, None, 38 0           batch_normalization_365[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_366 (Activation)      (None, None, None, 38 0           batch_normalization_366[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchNo (None, None, None, 19 576         conv2d_367[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_359 (Activation)      (None, None, None, 32 0           batch_normalization_359[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_361[0][0]             \n",
      "                                                                   activation_362[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, None, None, 76 0           activation_365[0][0]             \n",
      "                                                                   activation_366[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_367 (Activation)      (None, None, None, 19 0           batch_normalization_367[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_359[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_7[0][0]              \n",
      "                                                                   activation_367[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)              (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchNo (None, None, None, 44 1344        conv2d_372[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_372 (Activation)      (None, None, None, 44 0           batch_normalization_372[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)              (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)              (None, None, None, 38 1548288     activation_372[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchNo (None, None, None, 38 1152        conv2d_369[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchNo (None, None, None, 38 1152        conv2d_373[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_369 (Activation)      (None, None, None, 38 0           batch_normalization_369[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_373 (Activation)      (None, None, None, 38 0           batch_normalization_373[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)              (None, None, None, 38 442368      activation_369[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)              (None, None, None, 38 442368      activation_369[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)              (None, None, None, 38 442368      activation_373[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)              (None, None, None, 38 442368      activation_373[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePoo (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)              (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchNo (None, None, None, 38 1152        conv2d_370[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchNo (None, None, None, 38 1152        conv2d_371[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchNo (None, None, None, 38 1152        conv2d_374[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchNo (None, None, None, 38 1152        conv2d_375[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)              (None, None, None, 19 393216      average_pooling2d_36[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchNo (None, None, None, 32 960         conv2d_368[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_370 (Activation)      (None, None, None, 38 0           batch_normalization_370[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_371 (Activation)      (None, None, None, 38 0           batch_normalization_371[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_374 (Activation)      (None, None, None, 38 0           batch_normalization_374[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_375 (Activation)      (None, None, None, 38 0           batch_normalization_375[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchNo (None, None, None, 19 576         conv2d_376[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_368 (Activation)      (None, None, None, 32 0           batch_normalization_368[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_370[0][0]             \n",
      "                                                                   activation_371[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, None, None, 76 0           activation_374[0][0]             \n",
      "                                                                   activation_375[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_376 (Activation)      (None, None, None, 19 0           batch_normalization_376[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_368[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_8[0][0]              \n",
      "                                                                   activation_376[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1024)          2098176     global_average_pooling2d_2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1024)          0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 512)           524800      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 512)           0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 101)           51813       dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 24,477,573\n",
      "Trainable params: 8,748,325\n",
      "Non-trainable params: 15,729,248\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3 model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "transfer_learning_arch = base_model.output\n",
    "transfer_learning_arch = GlobalAveragePooling2D()(transfer_learning_arch)\n",
    "transfer_learning_arch = Dense(1024, activation='relu')(transfer_learning_arch)\n",
    "transfer_learning_arch = Dropout(0.4)(transfer_learning_arch)\n",
    "transfer_learning_arch = Dense(512, activation='relu')(transfer_learning_arch)\n",
    "transfer_learning_arch = Dropout(0.4)(transfer_learning_arch)\n",
    "predictions = Dense(101, activation='softmax')(transfer_learning_arch)\n",
    "\n",
    "transfer_learning_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "transfer_learning_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionV3 architecture:\n",
    "\n",
    "* Base Model Loading: It loads the InceptionV3 model with pre-trained weights from the ImageNet dataset. This base model is a powerful feature extractor capable of recognizing a wide range of visual patterns.\n",
    "\n",
    "* Customized Layers: It builds additional layers on top of the InceptionV3 base model.\n",
    "\n",
    "* Global Average Pooling: After the InceptionV3 layers, global average pooling is applied to reduce the spatial dimensions of the feature maps and summarize the features across all spatial locations.\n",
    "* Dense Layers: Two fully connected (dense) layers with 1024 and 512 units and ReLU activation functions are added. These layers help in capturing high-level features specific to the new task.\n",
    "* Dropout: Dropout layers with a dropout rate of 0.4 are inserted after each dense layer to reduce overfitting during training.\n",
    "* Output Layer: The final layer consists of 101 units (assuming a classification task with 101 classes) with a softmax activation function, which converts the model's output into class probabilities.\n",
    "\n",
    "* Model Compilation: The model is compiled, specifying the loss function, optimizer, and metrics for training.\n",
    "\n",
    "* Model Summary: The model summary is printed, which provides an overview of the architecture, including the number of trainable parameters in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6507 samples, validate on 2170 samples\n",
      "Epoch 1/15\n",
      "6507/6507 [==============================] - 124s - loss: 1.8833 - acc: 0.5915 - val_loss: 0.4862 - val_acc: 0.8737\n",
      "Epoch 2/15\n",
      "6507/6507 [==============================] - 92s - loss: 0.5494 - acc: 0.8535 - val_loss: 0.3566 - val_acc: 0.9115\n",
      "Epoch 3/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.3064 - acc: 0.9153 - val_loss: 0.3179 - val_acc: 0.9189\n",
      "Epoch 4/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.1879 - acc: 0.9481 - val_loss: 0.3018 - val_acc: 0.9263\n",
      "Epoch 5/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.1223 - acc: 0.9643 - val_loss: 0.2915 - val_acc: 0.9341\n",
      "Epoch 6/15\n",
      "6507/6507 [==============================] - 89s - loss: 0.0805 - acc: 0.9763 - val_loss: 0.2946 - val_acc: 0.9318\n",
      "Epoch 7/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.0636 - acc: 0.9817 - val_loss: 0.3043 - val_acc: 0.9332\n",
      "Epoch 8/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.0485 - acc: 0.9871 - val_loss: 0.3051 - val_acc: 0.9392\n",
      "Epoch 9/15\n",
      "6507/6507 [==============================] - 90s - loss: 0.0376 - acc: 0.9889 - val_loss: 0.3239 - val_acc: 0.9382\n",
      "Epoch 10/15\n",
      "6507/6507 [==============================] - 89s - loss: 0.0397 - acc: 0.9885 - val_loss: 0.3408 - val_acc: 0.9323\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "opt=Adadelta(lr=1.0, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "transfer_learning_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [ModelCheckpoint('transfer_learning_weights.h5', monitor='val_acc', save_best_only=True),\n",
    "            EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')]\n",
    "transfer_learning_model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_validation,Y_validation), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, this code sets up a neural network model, compiles it with specific settings, trains it on the provided data, and applies callbacks for monitoring and saving the best model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_average_accuracy_for_model(nn_model):\n",
    "    category_accuracy_dict = find_accuracy_per_category('./data', transfer_learning_model)\n",
    "    average_accuracy = 0\n",
    "    for category, scores in category_accuracy_dict.items():\n",
    "        print(category,\":\",scores[1])\n",
    "        average_accuracy += scores[1]\n",
    "    average_accuracy /= 101\n",
    "    print(\"Average accuracy : \",average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy : 0.9425913\n"
     ]
    }
   ],
   "source": [
    "find_average_accuracy_for_model(transfer_learning_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is much higher in the pretrained model.\n",
    "\n",
    "The higher accuracy achieved with a pre-trained model compared to training a model from scratch is due to the following key reasons:\n",
    "\n",
    "* Feature Extraction: Pre-trained models, such as InceptionV3 in the code, have already learned a wide range of useful features from a large and diverse dataset like ImageNet. These features include edge detectors, textures, shapes, and more. When we use a pre-trained model as a feature extractor, these learned features can be highly valuable for the specific task, reducing the need for the model to learn them from scratch. This is particularly important when we have a limited amount of data for your target task.\n",
    "\n",
    "* Transfer Learning: The pre-trained model serves as an excellent starting point for transfer learning. we are essentially leveraging the knowledge encoded in the pre-trained weights and fine-tuning the model for our specific classification task. Fine-tuning allows the model to adapt to the nuances of our dataset, learning task-specific information while retaining general knowledge acquired during pre-training.\n",
    "\n",
    "* Regularization: Pre-trained models often include regularization techniques, such as dropout and weight decay, that help prevent overfitting. These regularization methods improve the model's ability to generalize to new, unseen data.\n",
    "\n",
    "* Data Augmentation: Pre-trained models can benefit from data augmentation techniques, where you generate additional training examples by applying transformations like rotation, scaling, and cropping to your existing data. Data augmentation helps the model learn robust features that are invariant to such transformations.\n",
    "\n",
    "* Optimization: The pre-trained model is initialized with weights that are already in a reasonable range, which can accelerate convergence during training. In contrast, training a neural network from scratch may require more careful initialization and tuning of hyperparameters.\n",
    "\n",
    "* Reduced Training Time: Training a deep neural network from scratch can be computationally expensive and time-consuming, especially for large networks. Using a pre-trained model as a starting point allows you to train only a subset of layers, which typically requires fewer epochs and less computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
